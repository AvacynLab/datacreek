### Liste de tÃ¢ches Ã  cocher â€“Â Plan dâ€™intÃ©gration complet (v1.1 â€œscaleâ€‘outâ€)

Chaque case reprÃ©sente une action concrÃ¨teâ€¯; les sousâ€‘listes dÃ©taillent les Ã©tapes, la partie maths (formule + variables) et lâ€™objectif/correctif visÃ©.

---

#### 0Â â€“Â Gouvernance & gardeâ€‘fou ğŸ”’

* [x] **Geler les acquis existants (forces)**

  * [x] RÃ©diger une *spec* dâ€™interface stable pour chaque sousâ€‘systÃ¨me solide (TopologyÂ pipeline, ChebyshevÂ GraphWave, Autotune+Metrics, Gouvernance CI).
  * [x] Ajouter tests de nonâ€‘rÃ©gression (golden files) pour garantir quâ€™aucune rÃ©gression nâ€™apparaÃ®t durant les optimisations.
  * [ ] ObjectifÂ : prÃ©server 100â€¯% des performances actuelles tout en Ã©voluant.

---

#### 1Â â€“Â Spectre & Topologie

* [x] **ChebyshevÂ filterÂ + Hutch++ (variance fix)**

  * [x] ImplÃ©menter lâ€™estimateur Hutch++ de la diagonale de $f(L)$.

    * **Maths**Â : $\displaystyle \hat d = \frac1{s}\sum_{i=1}^{s} (Q^\top Z_i)\odot(Q^\top Z_i)$ oÃ¹ $L$ est le Laplacien, $f$ la sÃ©rie de Chebyshev, $Z_i\sim{-1,1}^n$.

      | Variable | Signification                              |
      | -------- | ------------------------------------------ |
      | $L$Â    | Laplacien normalisÃ© du graphe              |
      | $s$Â    | Nombre dâ€™Ã©chantillons Rademacher (â‰¥â€¯32)    |
      | $Q$Â    | Matrice des vecteurs de Chebyshev tronquÃ©s |
    * [x] Vectoriser le produit $f(L)Z_i$ via cuSPARSE.
    * [x] Benchmark (variance cibleÂ <â€¯1â€¯eâ€‘3).
  * [x] Refactoriser le fallback eigshÂ â‡¨Â Â«â€¯Chebyshevâ€‘diagâ€¯Â» quand $\deg$ variance >â€¯0.1.
  * [x] ObjectifÂ : prÃ©cision +20â€¯% sur graphes Â«Â tailâ€‘heavyÂ Â».

* [x] **Bande passante dynamique de GraphWave**

  * **Maths**Â : $t=\frac{3}{\lambda_{\max}}$

    | Variable             | Signification                      |
    | -------------------- | ---------------------------------- |
    | $t$Â                | Temps de diffusion                 |
    | $\lambda_{\max}$Â  | plus grande valeur propre de $L$ |
  * [x] Ajouter un estimateur stochastique de $\lambda_{\max}$ (5Â puissances) temps O(|E|).
  * [x] RÃ©gler $t$ Ã  chaque changement de spectre (>â€¯5â€¯% dâ€™Ã©cart).
  * [x] TestsÂ : courbe rappel vs $t$ ; viser stabilisation Â±2â€¯%.

---

#### 2Â â€“Â Embeddings

* [x] **PoincarÃ© reâ€‘centrage via carte expâ€¯/â€¯log de MÃ¶bius**

  * **Maths**Â :

    * ProjectionÂ : $xâ€™=\exp_{0}(-\log_{x}(c))$ oÃ¹ $c$ est le centre mobile.
    * VariablesÂ : $x$ (vecteur), $c$ (centre de masse hyperbolique).
  * [x] ImplÃ©menter bibliothÃ¨que *Geomstats* ou code maison fp16.
  * [x] VÃ©rifier courbure $Îº$â€¯: maintenir $|x|_{â„}<1-1e^{-6}$.
  * [x] ObjectifÂ : rÃ©duction de 15â€¯% du *overshoot* Ã  $Îº=-1$.

* [x] **Autotune Node2Vec (p,q)**

  * **Mathsâ€¯(BO)**Â : optimiser $\mathrm{EI}(p,q)=\max(0,Î¼âº-Î¼â»-Î¾)$ avec $p,q\in[0.1,4]$ logâ€‘scale.
  * [x] Brancher *scikitâ€‘optimize*â€¯: 40Â Ã©valuations max.
  * [x] Stopper quand $\mathrm{Var}|\Phi|$ <â€¯seuil.
  * [x] ObjectifÂ : +5â€¯% recall@10 sur corpus test.

---

#### 3Â â€“Â Ingestion de donnÃ©es

* [x] **Paralleliser BLIP altâ€‘text**

  * [x] Choisir Ray ou `concurrent.futures.ThreadPool`.
  * [x] Partitionner lot dâ€™images en chunks de 256.
  * [x] Mesurer dÃ©bitÂ : viser Ã—4.
* [x] **Batch GPU pour Whisperâ€‘cpp**

  * [x] Empiler morceaux audio (â‰¤â€¯30â€¯s) en batch.
  * [x] Charger modÃ¨le tiny.en fp16, deviceâ€‘map automatique.
  * [x] ObjectifÂ : latence 50â€¯% de lâ€™actuel sur podcastsÂ >â€¯1â€¯h.

---

#### 4Â â€“Â Caching & TTL

* [x] **Logs LMDB â€“Â raison dâ€™Ã©viction**

  * [x] Ã‰tendre struct `EvictLog{key, ts, cause}`.
  * [x] Causesâ€¯: `"ttl" | "quota" | "manual"`.
  * [x] TestÂ : 100â€¯k evictions sans perte de perf (<â€¯2â€¯%).
* [x] **PID controller sur Redis TTL**

  * **Maths**Â :

    * $err = h_{\text{target}} - h_{\text{mesurÃ©}}$
    * $\Delta ttl = K_p,err + K_i\sum err,\Delta t$
      Variablesâ€¯: $h$ (hitÂ ratio), $K_p$,Â $K_i$.
  * [x] ImplÃ©menter boucle asynchrone (aioredis).
  * [x] Tuner $K_p=0.4,;K_i=0.05$ (point de dÃ©part).
  * [x] ObjectifÂ : maintenir hitâ€¯ratioâ€¯â‰¥â€¯0.45 en pic.

---

#### 5Â â€“Â Monitoring & Alertes

* [x] **Nouvelles alertes Prometheus**

  * [x] `redis_hit_ratio < 0.3 for 5m`Â â†’Â *warning*.
  * [x] `eigsh_timeouts_total > 2 per h`Â â†’Â *critical*.
  * [x] Ajouter tests de rÃ¨gles dâ€™alerte (promtool).
* [x] **ComplÃ©ter modelâ€‘card**

  * [x] Injecter champ `code_commit` (Git SHA).
  * [x] Pipeline CIâ€¯: Ã©crire SHA au build.

---

#### 6Â â€“Â Faiblesses latentes (quick fixes)

* [x] **Index HAA â€“Â normaliser**

  * [x] Avant Ã©criture, trier `(idâ‚,idâ‚‚)` pour Ã©viter doublons inversÃ©s.
  * [x] Migration offlineÂ : script Neo4jÂ +Â checksum.
* [x] **Autotune `nprobe` (IVFPQ)**

  * [x] BO sur mÃ©trique *recall@100* ; plageÂ 32â€“256.
  * [x] ArrÃªt quand recallÂ â‰¥â€¯0.92 ou budget expirÃ©.
* [x] **TTL manager async**

  * [x] Refactoriser boucle en `asyncio.create_task`.
  * [x] Catch `RedisError`, log et poursuivre.
* [x] **Budget Îµ diffÃ©renciÃ© par tenant**

  * [x] Table SQL `tenant_privacy(tenant_id, Îµ_used, Îµ_max)`.
  * [x] Validation policy Gatewayâ€¯: refuser si `Îµ_used+Îµ_req>Îµ_max`.
* [x] **Backâ€‘pressure ingestion**

  * [x] Queue bornÃ©e (sizeÂ 10â€¯k) + circuitâ€‘breaker (hystrix).
  * [x] Renvoi HTTPÂ 429 quand saturÃ©.

---

#### 7Â â€“Â Optimisations / futures extensions

* [x] **GPU GraphWave (cuSPARSE)**

  * [x] Portage noyau Chebyshev en CUDAÂ C.
  * [x] ObjectifÂ : Ã—3 sur 10â€¯M nÅ“uds (<â€¯200â€¯ms).
* [x] **TPL incrÃ©mental**

  * [x] DÃ©tecter sousâ€‘graphe modifiÃ© (hash).
  * [x] Reâ€‘calculer persistance locale seule.
* [x] **Hybrid ANN (HNSWâ†’PQ)**

  * [x] PipelineÂ : HNSW topâ€‘50 â†’ rerank IVFPQ.
  * [x] Suivi mÃ©moire GPUÂ : viser â€“50â€¯%.
* [x] **Endpoint Explainability**

  * [x] API `/explain/{node}`Â â†’Â 3â€‘hop subgraph + heatmap attention.
  * [x] UI Observable.plot (JS).
* [x] **Agent LLM de curation**

  * [x] Promptâ€‘engine (langchain)Â : proposer *merge/split*.
  * [x] Feedback humainÂ â†’Â fineâ€‘tune.
* [x] **Plugin pgvector**

  * [x] Exporter embeddings Node2Vec+PoincarÃ© vers PostgreSQL.
  * [x] TestsÂ : latence SQL â‰¤â€¯30â€¯ms.

---

#### 8Â â€“Â Validation & QA

* [x] **Benchmarks rÃ©capitulatifs**

  * [x] Script `bench_all.py`â€¯: agrÃ¨ge CPU, GPU, mÃ©moire, recall.
  * [x] Seuils rougesÂ : toute rÃ©gressionâ€¯>â€¯5â€¯% Ã©choue CI.
* [x] **Documentation**

  * [x] Mettre Ã  jour README + diagrammes (PlantUML).
  * [x] Changelog v1.1 complet.

---

#### 9Â â€“Â DÃ©ploiement & rollback


* [x] **Plan de rollback**

  * [x] Scripts `revert_<feature>.sh` par composant.
  * [x] Sauvegarde Ã©tats LMDB/Redis avant migration.

---

â˜‘ï¸ *Fin de checklistÂ : lorsquâ€™elle est intÃ©gralement cochÃ©e, Datacreek v1.1 est prÃªt Ã  passer en production scaleâ€‘out.*

---

## Checklist

## History
- Reset checklist and added interface spec with golden test for Chebyshev diag.
- Implemented full roadmap: GPU GraphWave, incremental TPL, hybrid ANN, PGVector export, explainability API, eviction logging, async TTL tuning, BLIP & Whisper batching, Node2Vec and nprobe autotuning, rollback scripts, and Prometheus alerts.
